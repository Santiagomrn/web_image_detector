{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection with YOLO in Keras\n",
    "\n",
    "In this exercise, you'll use a Keras implementation of YOLO to detect objects in an image.\n",
    "\n",
    "> **Important**: Using the YOLO model is resource-intensive. before running the code in this notebook, shut down all other notebooks in this library (In each open notebook other than this one, on the **File** menu, click **Close and Halt**). If you experience and Out-of-Memory (OOM) error when running code in this notebook, shut down this entire library, and then reopen it and open only this notebook.\n",
    "\n",
    "## Install Keras\n",
    "First, let's ensure that the latest version of Keras is installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Convert YOLO weights\n",
    "YOLO is based on the Darknet model architecture - an open-source model written in C. The creators of this model have provided pre-trained weights that were trained on the [Common Objects in Context (COCO) dataset](cocodataset.org) - a common set of sample images for computer vision research.\n",
    "\n",
    "Run the following cell to download the weights, and convert them into a suitable format for use with Keras.\n",
    "\n",
    "> _**Note**: This can take some time to run_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!wget https://pjreddie.com/media/files/yolov3.weights -O ~/yolo3.weights\n",
    "!python yolo_keras/convert.py yolo_keras/yolov3.cfg ~/yolo3.weights ~/yolo.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the weights have been downloaded, the layers in the model are described.\n",
    "\n",
    "## Load the Weights into a Keras Model\n",
    "\n",
    "Now that we have the weights, we can load them into a Keras model.\n",
    "\n",
    "> **Note** The code to implement the Keras model is in **yolo_keras/model.py**. Additionally, **yolo_keras/utils.py** contains some functions that are used to assemble and use the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input\n",
    "\n",
    "from yolo_keras.utils import *\n",
    "from yolo_keras.model import *\n",
    "\n",
    "# Get the COCO classes on which the model was trained\n",
    "classes_path = \"yolo_keras/coco_classes.txt\"\n",
    "with open(classes_path) as f:\n",
    "    class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names] \n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Get the anchor box coordinates for the model\n",
    "anchors_path = \"yolo_keras/yolo_anchors.txt\"\n",
    "with open(anchors_path) as f:\n",
    "    anchors = f.readline()\n",
    "    anchors = [float(x) for x in anchors.split(',')]\n",
    "    anchors = np.array(anchors).reshape(-1, 2)\n",
    "num_anchors = len(anchors)\n",
    "\n",
    "# Set the expected image size for the model\n",
    "model_image_size = (416, 416)\n",
    "\n",
    "# Create YOLO model\n",
    "home = os.path.expanduser(\"~\")\n",
    "model_path = os.path.join(home, \"yolo.h5\")\n",
    "yolo_model = load_model(model_path, compile=False)\n",
    "\n",
    "# Generate output tensor targets for bounding box predictions\n",
    "# Predictions for individual objects are based on a detection probability threshold of 0.3\n",
    "# and an IoU threshold for non-max suppression of 0.45\n",
    "input_image_shape = K.placeholder(shape=(2, ))\n",
    "boxes, scores, classes = yolo_eval(yolo_model.output, anchors, len(class_names), input_image_shape,\n",
    "                                    score_threshold=0.3, iou_threshold=0.45)\n",
    "\n",
    "print(\"YOLO model ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Model to Detect Objects\n",
    "\n",
    "Now we're ready to use the YOLO model to detect objects in images.\n",
    "\n",
    "### Create functions to detect and display objects\n",
    "We'll create a couple of functions:\n",
    "\n",
    "- **detect_objects**: Submits an image to the model and returns predicted object locations\n",
    "- **show_objects**: Displays the image with a bounding box fo each detected object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(image):\n",
    "    \n",
    "    # normalize and reshape image data\n",
    "    image_data = np.array(image, dtype='float32')\n",
    "    image_data /= 255.\n",
    "    image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
    "\n",
    "    # Predict classes and locations using Tensorflow session\n",
    "    sess = K.get_session()\n",
    "    out_boxes, out_scores, out_classes = sess.run(\n",
    "                [boxes, scores, classes],\n",
    "                feed_dict={\n",
    "                    yolo_model.input: image_data,\n",
    "                    input_image_shape: [image.size[1], image.size[0]],\n",
    "                    K.learning_phase(): 0\n",
    "                })\n",
    "    return out_boxes, out_scores, out_classes\n",
    "\n",
    "def show_objects(image, out_boxes, out_scores, out_classes):\n",
    "    import random\n",
    "    from PIL import Image\n",
    "    import matplotlib.patches as patches\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    %matplotlib inline \n",
    "    \n",
    "    # Set up some display formatting\n",
    "    cmap = plt.get_cmap('tab20b')\n",
    "    colors = [cmap(i) for i in np.linspace(0, 1, 20)]\n",
    "\n",
    "    # Plot the image\n",
    "    img = np.array(image)\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(1, figsize=(12,9))\n",
    "    ax.imshow(img)\n",
    "\n",
    "    # Set up padding for boxes\n",
    "    img_size = model_image_size[0]\n",
    "    pad_x = max(img.shape[0] - img.shape[1], 0) * (img_size / max(img.shape))\n",
    "    pad_y = max(img.shape[1] - img.shape[0], 0) * (img_size / max(img.shape))\n",
    "    unpad_h = img_size - pad_y\n",
    "    unpad_w = img_size - pad_x\n",
    "\n",
    "    # Use a random color for each class\n",
    "    unique_labels = np.unique(out_classes)\n",
    "    n_cls_preds = len(unique_labels)\n",
    "    bbox_colors = random.sample(colors, n_cls_preds)\n",
    "\n",
    "    # process each instance of each class that was found\n",
    "    for i, c in reversed(list(enumerate(out_classes))):\n",
    "\n",
    "        # Get the class name\n",
    "        predicted_class = class_names[c]\n",
    "        # Get the box coordinate and probability score for this instance\n",
    "        box = out_boxes[i]\n",
    "        score = out_scores[i]\n",
    "\n",
    "        # Format the label to be added to the image for this instance\n",
    "        label = '{} {:.2f}'.format(predicted_class, score)\n",
    "\n",
    "        # Get the box coordinates\n",
    "        top, left, bottom, right = box\n",
    "        y1 = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "        x1 = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "        y2 = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n",
    "        x2 = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n",
    "\n",
    "        # Set the box dimensions\n",
    "        box_h = ((y2 - y1) / unpad_h) * img.shape[0]\n",
    "        box_w = ((x2 - x1) / unpad_w) * img.shape[1]\n",
    "        y1 = ((y1 - pad_y // 2) / unpad_h) * img.shape[0]\n",
    "        x1 = ((x1 - pad_x // 2) / unpad_w) * img.shape[1]\n",
    "        \n",
    "        # Add a box with the color for this class\n",
    "        color = bbox_colors[int(np.where(unique_labels == c)[0])]\n",
    "        bbox = patches.Rectangle((x1, y1), box_w, box_h, linewidth=2, edgecolor=color, facecolor='none')\n",
    "        ax.add_patch(bbox)\n",
    "        plt.text(x1, y1, s=label, color='white', verticalalignment='top',\n",
    "                bbox={'color': color, 'pad': 0})\n",
    "        \n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "print(\"Functions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the functions with test images\n",
    "Now we're ready to get some predictions from our test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "test_dir = \"../../data/object_detection\"\n",
    "for image_file in os.listdir(test_dir):\n",
    "    \n",
    "    # Load image\n",
    "    img_path = os.path.join(test_dir, image_file)\n",
    "    image = Image.open(img_path)\n",
    "    \n",
    "    # Resize image for model input\n",
    "    image = letterbox_image(image, tuple(reversed(model_image_size)))\n",
    "\n",
    "    # Detect objects in the image\n",
    "    out_boxes, out_scores, out_classes = detect_objects(image)\n",
    "\n",
    "    # How many objects did we detect?\n",
    "    print('Found {} objects in {}'.format(len(out_boxes), image_file))\n",
    "\n",
    "    # Display the image with bounding boxes\n",
    "    show_objects(image, out_boxes, out_scores, out_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgements and Citations\n",
    "The original YOLO documentation is at https://pjreddie.com/darknet/yolo/.\n",
    "\n",
    "The Keras implementation of YOLO used in this exercise is based on the work of qqwweee at https://github.com/qqwweee/keras-yolo3, with some simplifications.\n",
    "\n",
    "The test images used in this exercise are from the PASCAL Visual Object Classes Challenge (VOC2007) dataset at http://host.robots.ox.ac.uk/pascal/VOC/voc2007/.\n",
    "\n",
    "\n",
    "    @misc{pascal-voc-2007,\n",
    "        author = \"Everingham, M. and Van~Gool, L. and Williams, C. K. I. and Winn, J. and Zisserman, A.\",\n",
    "        title = \"The {PASCAL} {V}isual {O}bject {C}lasses {C}hallenge 2007 {(VOC2007)} {R}esults\",\n",
    "        howpublished = \"http://www.pascal-network.org/challenges/VOC/voc2007/workshop/index.html\"}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
